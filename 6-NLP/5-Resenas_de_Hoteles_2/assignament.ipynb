{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba un conjunto de datos diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones\n",
    "Ahora que se ha aprendido acerca del uso de la libreria NLTK para asignar sentimiento al texto, prueba un conjunto de datos diferente. Probablemente necesitarás hacer algo más de procesamiento de datos, por lo cual, crear un notebook y documenta tu proceso de pensamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   Target  1048575 non-null  int64 \n",
      " 1   ID      1048575 non-null  int64 \n",
      " 2   Date    1048575 non-null  object\n",
      " 3   flag    1048575 non-null  object\n",
      " 4   User    1048575 non-null  object\n",
      " 5   Text    1048575 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 48.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186342</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Madelinedugganx</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186409</td>\n",
       "      <td>Fri May 29 07:33:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>OffRoad_Dude</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186429</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Falchion</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186445</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jonasobsessedx</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186607</td>\n",
       "      <td>Fri May 29 07:33:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sugababez</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target          ID                          Date      flag  \\\n",
       "0             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1048570       4  1960186342  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
       "1048571       4  1960186409  Fri May 29 07:33:43 PDT 2009  NO_QUERY   \n",
       "1048572       4  1960186429  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
       "1048573       4  1960186445  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
       "1048574       4  1960186607  Fri May 29 07:33:45 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    User                                               Text  \n",
       "0          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4               joy_wolf                      @Kwesidei not the whole crew   \n",
       "...                  ...                                                ...  \n",
       "1048570  Madelinedugganx           My GrandMa is making Dinenr with my Mum   \n",
       "1048571     OffRoad_Dude  Mid-morning snack time... A bowl of cheese noo...  \n",
       "1048572         Falchion  @ShaDeLa same here  say it like from the Termi...  \n",
       "1048573   jonasobsessedx             @DestinyHope92 im great thaanks  wbuu?  \n",
       "1048574        sugababez               cant wait til her date this weekend   \n",
       "\n",
       "[1048575 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "DataTweets= ('./Data/tweets.csv')\n",
    "df = pd.read_csv(DataTweets, encoding='ISO-8859-1')\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos y descargamos los recursos de la libreria NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar el análisis de sentimientos, es una buena práctica realizar algunas tareas de preprocesamiento para limpiar y preparar los textos de tus tweets. Algunas de estas tareas comunes incluyen la tokenización y la eliminación de palabras vacías (stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización: dividir el texto en palabras individuales\n",
    "df['Text'] = df['Text'].apply(word_tokenize)\n",
    "\n",
    "# Eliminación de stopwords: eliminar palabras comunes que no aportan mucho significado al análisis\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Text'] = df['Text'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos proceder a realizar el análisis de sentimientos en los textos de los tweets. Para esto, puedes usar diferentes enfoques y herramientas, pero en esta ocasión, utilizaré el analizador de sentimientos VADER (Valence Aware Dictionary and sEntiment Reasoner) de NLTK, que es especialmente útil para textos cortos y de redes sociales como los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar solo una muestra del conjunto de datos\n",
    "sample_size = 10000  # Tamaño de la muestra\n",
    "df_sample = df.sample(n=sample_size, random_state=42)  # Muestreo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Inicializar el analizador de sentimientos\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "[Neutral, Neutral, Neutral, Neutral, Neutral]                                                                                                                                                                                                            275\n",
       "[Neutral, Neutral, Neutral, Neutral, Neutral, Neutral]                                                                                                                                                                                                   246\n",
       "[Neutral, Neutral, Neutral, Neutral]                                                                                                                                                                                                                     239\n",
       "[Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral]                                                                                                                                                                                          225\n",
       "[Neutral, Neutral, Neutral]                                                                                                                                                                                                                              219\n",
       "                                                                                                                                                                                                                                                        ... \n",
       "[Neutral, Positivo, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Positivo, Neutral, Neutral, Neutral, Neutral, Neutral, Positivo, Neutral, Positivo, Positivo]                                                                  1\n",
       "[Neutral, Neutral, Neutral, Neutral, Neutral, Positivo, Neutral, Neutral, Neutral, Neutral, Neutral, Positivo, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral]      1\n",
       "[Neutral, Neutral, Positivo, Neutral, Negativo, Neutral, Neutral, Neutral, Negativo, Neutral, Neutral, Neutral, Neutral]                                                                                                                                   1\n",
       "[Neutral, Neutral, Positivo, Neutral, Positivo, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Neutral, Negativo, Neutral, Neutral, Neutral, Positivo, Neutral, Neutral, Neutral, Neutral]                                                 1\n",
       "[Negativo, Neutral, Negativo, Neutral, Neutral, Negativo, Neutral, Neutral, Neutral]                                                                                                                                                                       1\n",
       "Name: count, Length: 3699, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_sentiment(text):\n",
    "    if isinstance(text, list):\n",
    "        # Si es una lista de textos, aplicar la función a cada texto individualmente\n",
    "        return [analyze_sentiment(t) for t in text]\n",
    "    else:\n",
    "        # Si es un solo texto, calcular el sentimiento usando VADER\n",
    "        scores = sid.polarity_scores(text)\n",
    "        if scores['compound'] > 0.05:\n",
    "            return 'Positivo'\n",
    "        elif scores['compound'] < -0.05:\n",
    "            return 'Negativo'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "            \n",
    "# Aplicar la función de análisis de sentimientos a la columna 'Text' de la muestra\n",
    "df_sample['Sentiment'] = df_sample['Text'].apply(analyze_sentiment)\n",
    "\n",
    "# Contar la cantidad de tweets con cada tipo de sentimiento\n",
    "sentiment_counts = df_sample['Sentiment'].value_counts()\n",
    "\n",
    "sentiment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "Con la elaboracion de este análisis podemos comparar los sentimientos expresados en diferentes categorías, como por ejemplo, por usuario, por tema o por ubicación geográfica. Esto nos ayuda a identificar si hay alguna variación en los sentimientos expresados por diferentes grupos.\n",
    "Tambien podemos analizar cómo eventos específicos afectan los sentimientos expresados en los tweets. Por ejemplo, podríamos observar si un evento negativo causa un aumento en los sentimientos negativos expresados en Twitter.\n",
    "En resumen, el análisis de sentimientos nos proporciona información valiosa sobre cómo se sienten las personas en relación con ciertos temas, eventos o situaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
